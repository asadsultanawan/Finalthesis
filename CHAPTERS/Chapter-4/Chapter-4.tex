\chapter{Training \& Testing of the
Classifier}
\label{Chapter 4}
Recall from the last chapter that Convolutional Neural Networks (CNNs) are used
in the training of a model for a classifier. Classification is the process
of putting a tag on an image from a set of class labels. This chapter is about the
training of classifier for a dataset of images of five classes.
The step by step process of training a classifier is explained in detail in this chapter. Results obtained from the testing of the classifier by varying certain parameters are recorded and attached
in the latter part of the chapter.
\section{Formation of Dataset}
In deep learning techniques for classification of images, we have
images examples which are input to to the system for training purposes
to train a model and then it is tested for a set of images to get
label from the given classes. This set of images is called dataset.
The dataset is divided into training and test dataset by a specific ratio.

In this project we have five different classes of vehciles i.e. Bus, Car, Truck, Motorcycle
and Hiace. There are a total of 10000 images with 2000 images of each 
class. These images are downloaded from Google search results and from already available
datasets and from websites providing licensed free images like Flickr. APIs are available which
can be used along with a simple Python script to download a lot of images.
Using matplotlib in python, we can plot some of the images with the output as
shown in listing \ref{listing:4.1} and plot is attached in figure
\ref{fig:4.1}.
\linespread{1.0}
\begin{listing}[H]
\begin{minted}[bgcolor=bg,
    frame = lines,
    framesep = 2mm]{python}
import matplotlib.pyplot as plt
from matplotlib.image import imread  
path  = './images/'
for i in range(9):
    plt.subplot(330+1+i)
    filename = path + 'image_'+ str(i) + '.jpg'
    image = imread(filename)
    plt.imshow(image)    
    plt.show()
\end{minted}
\caption{Python script to plot some images from each class}
\label{listing:4.1}
\end{listing}

\begin{figure}[H]
    \centering
    \captionsetup{justification = centering}
    \includegraphics[scale = 0.8]{CHAPTERS/Chapter-4/Images/4.1.png}
    \caption{Plot of some images from each class} 
    \label{fig:4.1}
  \end{figure}

\subsection{Data Augmentation}
Increasing the size of dataset makes the deep learning model to learn and classify images more accurately. This problem of lack of sufficient data can be solved using technique of data augmentation which is used to increase the size of available set of images.
Data augmentation is the process of applying techniques like shifting, flipping, rotating and varying the brightness etc on images to introduce variations among them.
This technique is used within the code using Keras.
\section{Setting of Workspace for the Project}
There are a lot of images to be processed. To process images, high end GPU is
needed. Due to unavailability of an Nvidia GPU on the system, we used Google Colab.
It is an online platform having high end GPUs free provided by Google for training
up to 12 hours. Enabling a GPU in the notebook settings can accelerate the process of
training.
\section{Process of Training}
Keras is one of the leading high level API for neural networks. It contains
many modules such as layers, cost functions, activation functions, initialization
schemes and regularization schemes. This project uses Keras for training purposes.
\subsection{Conversion of Images and Labels to Numpy Arrays}
After importing all the necessary packages, we are all set to pre process our data.
Recall to chapter 2, where we studied the basics of an image. In Keras image has two
representations i.e. (width, height, color\_channels) and (color\_channels, width, height).
First approach is called as channels first approach and the latter is called as
channels last approach. We will use the channels last approach.
First step is to read the images from the folder mounted from Google drive,
Labels are assigned to classes from 0 to 4. Keras load\_img() loads image from the folder given
target size. Target size for this project is chosen as 128 by 128. This means width and height,
both are 128. Color channels for RGB images are 3. Images are then converted to numpy arrays using
Keras img\_to\_array() method. Labels are stored as 0, 1, 2, 3, 4 based on the class of image (as data is renamed).
A section of code for this implementation is shown in listing \ref{listing:4.2}.

\begin{longlisting}
    \begin{minted}[bgcolor=bg,
        frame = lines,
        framesep = 2mm]{python}
folder = '/content/Input_data/'
images = np.zeros((num_of_images,img_rows,img_cols,color_channels))
labels = np.zeros(num_of_images)
i = 0
# enumerate files in the directory
for file in os.listdir(folder):
# determine class
    if file.startswith('bus'):
        output = 0
    elif file.startswith('car'):
        output = 1
    elif file.startswith('bike'):
        output = 2
    elif file.startswith('hiace'):
        output = 3
    else:
        output = 4
    # load image
    img = load_img(folder + file, target_size=(img_rows,img_cols))
    # convert to numpy array
    img = img_to_array(img)
    # store
    images[i] = img
    labels[i] = output
    i = i+1
\end{minted}
\caption{Conversion of Images to Numpy arrays}
\label{listing:4.2}
\end{longlisting}
The images array has a pattern (num\_of\_images, rows, cols, color\_channels). It
means that it has a shape (10000, 128, 128, 3). This is a 4D tensor. There are 10000
images with each image having 128, $128\times 3$ matrices i.e. each $128\times 3$ matrix has
128 rows with each row containing 3 columns with information of 3 colors.
The labels array is a 1D tensor with 10000 labels.
\subsection{Train-Test Division}
We have to divide the data into two parts, train and test. The training data
is used to for training purposes and when the model is trained then it is
used to test the model using the test images and test labels. We used a ratio of 75\% and
25\% for train and test respectively. The package used for this purpose is the
Scikit-learn train\_test\_split. Listing \ref{listing:4.3} shows splitting of
data into train and test.

\begin{listing}[H]
    \begin{minted}[bgcolor=bg,
        frame = lines,
        framesep = 2mm]{python}
train_images, test_images, train_labels, test_labels = 
train_test_split(images, labels, test_size = 0.25, random_state = 42)
\end{minted}
\caption{Train-test split}
\label{listing:4.3}
\end{listing}
There is another technique for splitting of data. We make two directories
train and test and randomly divide the images into these directories and then
convert them into numpy array. Here we have first converted the images
into arrays, split them into train and test and then we can save them back into
directories by converting them into images from array using PIL from\_array
function.

\subsection{Mean Correction}
After converting to float 32 and normalizing by 255, we have to subtract mean pixel.
Listing \ref{listing:4.4} illustrates the mean correction.

\begin{listing}[H]
    \begin{minted}[bgcolor=bg,
        frame = lines,
        framesep = 2mm]{python}
train_images = train_images.astype('float32') / 255
test_images = test_images.astype('float32') / 255

if subtract_pixel_mean:
    x_train_mean = np.mean(train_images, axis=0)
    train_images -= x_train_mean
    test_images -= x_train_mean

train_labels = to_categorical(train_labels,num_classes)
test_labels = to_categorical(test_labels,num_classes)
    \end{minted}
    \caption{Mean correction}
\label{listing:4.4}
\end{listing}
\noindent The last two lines are categorical labeling for using labels fit for Keras.
\subsection{Defining the Model}
Recall from chapter \ref{Chapter 3}, a CNN model consists of various layers including
conv2D, Activation, MaxPoooling2D, Flatten and Dense layer. Listing \ref{listing:4.5}
defines the training Model.

\begin{longlisting}
    \begin{minted}[bgcolor=bg,
        frame = lines,
        framesep = 2mm]{python}
#Model
model = Sequential()
model.add(Conv2D(32, (3, 3), padding='same', activation = "relu",
                         input_shape=train_images.shape[1:]))
model.add(Conv2D(32, (3, 3)), activation = "relu"))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))   

model.add(Conv2D(64, (3, 3), padding='same', activation = "relu"))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25)) 
     
model.add(Flatten())

model.add(Dense(64))
model.add(Activation('relu'))
model.add(Dropout(0.5)) 

model.add(Dense(num_classes))
model.add(Activation('softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam',
metrics=['accuracy'])
    \end{minted}
    \caption{Defining the Model}
\label{listing:4.5}
\end{longlisting}
Last three lines defines the compilation process of the Model. 
For more than two classes, loss is categorical\_crossentropy. For two
classes it is binary\_crossentropy. There are many optimizers in Keras i.e.
SGD, Adam, RMSprop, Adamax etc. Here we have used Adam. Accuracy metrics calculates how
often prediction equals labels.
\subsection{Fitting the Model}
Here the process of training starts. We have two functions used in Keras. One
is model.fit and other is model.fit\_generator. As we discussed in section 4.1.1
about data augmentation. Here we have implemented data augmentation using a\
an if-else logic. We have also defined a validation set. Validation data tells us about the
behavior of the model to an unseen data.

The number of times a model goes through the data is termed as `epochs'.
We have to determine the specific number of epochs for which the training process has to
run. If we run the process above that number, the training accuracy will
increase. But when we test that model with the test data, the accuracy of the model
will be lower than the training accuracy. This process is called `\textit{overfitting}'.
We have to avoid the overfitting. We use validation data which shows us the validation accuracy
and loss after each epoch. Listing \ref{listing:4.6} shows the code for training process.

\begin{longlisting}
    \begin{minted}[bgcolor=bg,
        frame = lines,
        framesep = 2mm
        ]{python}
if not data_augmentation:
    print('Not using data augmentation.')
    history = model.fit(train_images, train_labels, validation_data =
    (test_images, test_labels), batch_size = batch_size, epochs = n_epochs)
else:
    datagen = ImageDataGenerator(
        zca_epsilon=1e-06,
        rotation_range=0,  
        width_shift_range=0.1,
        height_shift_range=0.1,
        shear_range=0.,
        zoom_range=0.,
        channel_shift_range=0.,
        fill_mode='nearest',
        cval=0.,
        rescale=None,
        preprocessing_function=None,
        data_format=None,
        validation_split=0.0)
    
    datagen.fit(train_images)
    
    history = model.fit_generator(datagen.flow(train_images, train_labels,
    batch_size = batch_size),validation_data=(test_images, test_labels),
    epochs = n_epochs)    
    \end{minted}
    \caption{Training the Model}
\label{listing:4.6}
\end{longlisting}
\subsection{Plotting the Accuracy and Loss}
A specific model has a specific accuracy upto which it can detect an unknown data.
Increasing epochs will not increase the accuracy, it basically overfits
the model. For a certain model, we have to find a specific number
of epochs. For this we plot the accuracy and loss of training and
validation data. Listing \ref{listing:4.7} shows the script for plotting the accuracy and
loss of training and validation data.

\begin{longlisting}
    \begin{minted}[bgcolor=bg,
        frame = lines,
        framesep = 2mm]{python}
plt.grid()
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()
# summarize history for loss
plt.grid()
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()
\end{minted}
\caption{Training, validation accuracy \& loss vs. epochs}
\label{listing:4.7}
\end{longlisting}

\subsection{Saving Model \& Weights}
After successful training of model, we have to resuse it. We can directly test it for one time
when the Colab is not recycled. So the better approach is to save the model
and then evalaute it on test data. Model is stored as .h5 file in the root directory.
Listing \ref{listing:4.8} shows the script for saving the weights.

\begin{listing}[H]
    \begin{minted}[bgcolor=bg,
        frame = lines,
        framesep = 2mm]{python}
# Save model and weights
if not os.path.isdir(save_dir):
    os.makedirs(save_dir)
model_path = os.path.join(save_dir, model_name)
model.save(model_path)
print('Saved trained model at %s ' % model_path)
\end{minted}
\caption{Saving the Model}
\label{listing:4.8}
\end{listing}
\section{Evaluation of Model}
Loading the Model saved in the root directory and test it using evalaute function
tells us the accuracy of Model on the test data. Listing \ref{listing:4.9} shows the script for
evalaution.
\begin{longlisting}
    \begin{minted}[bgcolor=bg,
        frame = lines,
        framesep = 2mm]{python}
#Load Model
loaded_model = load_model("saved_models/model.h5")
#Evaluate Model
test_loss, test_acc = loaded_model.evaluate(test_images, test_labels)
print('Accuarcy of the model:', test_acc)
\end{minted}
\caption{Evaluating the Model}
\label{listing:4.9}
\end{longlisting}
\subsection{Two Class Problem \& Results}
We started with two class problem, Bus \& Car and recorded the results from 5 to 30 epochs.
The loss was binary\_crossentropy in this case. 
The training accuracy recorded after 20 epochs was 95.08\% and training
loss was 14.7\%. The test set was choosen as validation data and validation accuracy after 5 epochs 
was 96.10\% and validation loss was 10.48\%.
Here we attach the results only for 5 epochs and 20 epochs
in figure \ref{fig:4.2} and \ref{fig:4.3}.
\begin{figure}[H]
    \centering
    \captionsetup{justification = centering}
    \includegraphics[scale = 0.63]{CHAPTERS/Chapter-4/Images/4.2}
    \caption{Training results for two class problem after 5 epochs} 
    \label{fig:4.2}
\end{figure}
\begin{figure}[H]
    \centering
    \captionsetup{justification = centering}
    \includegraphics[scale = 0.63]{CHAPTERS/Chapter-4/Images/4.3}
    \caption{Training results for two class problem after 20 epochs} 
    \label{fig:4.3}
\end{figure}
After 20 epochs for this model, the validation loss increases which indicate
that we have to train that model up to 20 epochs. 

\subsection{Five Class Probem \& Results}
We started with two class problem and extended the model to five classes
which is our desired task. The loss function in this case is categorical\_crossentropy.
The model used for five class is a customized VGG-16. The details of the
model are shown in figure \ref{model_summary}.
\begin{figure}[H]
    \centering
    \captionsetup{justification = centering}
    \includegraphics[scale = 0.8]{CHAPTERS/Chapter-4/Images/summary-01.jpg}
    \caption{Training results for two class problem after 20 epochs} 
    \label{model_summary}
\end{figure}
The optimizer used is RMSprop with
learning rate 0.0001. We started with 5 epochs, then 10 upto 20. The plot of training
and validation accuracy and training and validation loss is plotted using Python
matplotlib and it is observed that near to 20 the validation loss
increases and validation accuracy decreases. So we stopped at 20 epochs
and recorded the results. The plots are shown in
figure \ref{fig:4.4}.
\begin{figure}[htbp]
    \centering
    \begin{subfigure}[t]{0.45\textwidth}
        \includegraphics[scale = 0.52]{CHAPTERS/Chapter-4/Images/4.4a}
        \caption{Training \& validation accuracy}
        \label{fig:4.4a}
    \end{subfigure}
    \begin{subfigure}[t]{0.45\textwidth}
        \includegraphics[scale = 0.52]{CHAPTERS/Chapter-4/Images/4.4b}
        \caption{Training \& validation loss}
        \label{fig:4.4b}
    \end{subfigure}
    \caption[]{Model accuracy \& model loss}
    \label{fig:4.4}
  \end{figure}
  The loss was binary\_crossentropy in this case. 
  The training accuracy recorded after 20 epochs was 93\% and training
  loss was 22.3\%. The test set was choosen as validation data and
  validation accuracy after 20 epochs 
  was 92.40\% and validation loss was 24\%.
  Here we attach the results only for 10 epochs and 20 epochs
  in figure \ref{fig:4.5} and \ref{fig:4.6}.
\begin{figure}[H]
    \centering
    \captionsetup{justification = centering}
    \includegraphics[scale = 0.53]{CHAPTERS/Chapter-4/Images/4.5}
    \caption{Training results for five class problem after 10 epochs} 
    \label{fig:4.5}
\end{figure}
\begin{figure}[H]
    \centering
    \captionsetup{justification = centering}
    \includegraphics[scale = 0.68]{CHAPTERS/Chapter-4/Images/4.6}
    \caption{Training results for five class problem after 20 epochs} 
    \label{fig:4.6}
\end{figure}
\section{Graphical User Interface}
To observe the results in a concrete way, we have to pass test images
one by one and obtain the corresponding labels. For this purpose,
we made a Graphical User Interface (GUI) using tkinter package of Python.
As discussed earlier that we have saved the model in a folder named
as saved\_models in the root directory. This model can be downloaded to local
disks of the computer (As tkinter uses the GUI of computer, it can not
run on Colab). Then from the test directory, all the images one by one are passed
and corresponding labels are displayed. Some examples are shown in
figure \ref{fig:4.7}.

\begin{figure}[htbp]
    \centering
    \begin{subfigure}[t]{0.3\textwidth}
        \fbox{\includegraphics[width = 4.5cm, height = 4.5cm]{CHAPTERS/Chapter-4/Images/4.7a}}
        \caption{}
        \label{fig:4.7a}
    \end{subfigure}
    \begin{subfigure}[t]{0.3\textwidth}
        \fbox{\includegraphics[width = 4.5cm, height = 4.5cm]{CHAPTERS/Chapter-4/Images/4.7b}}
        \caption{}
        \label{fig:4.7b}
    \end{subfigure}
    \begin{subfigure}[t]{0.3\textwidth}
      \fbox{\includegraphics[width = 4.5cm, height = 4.5cm]{CHAPTERS/Chapter-4/Images/4.7c}}
      \caption{}
      \label{fig:4.7c}
  \end{subfigure}
    \captionsetup{justification = centering}
    \caption[]{Test images and labels on a GUI}
    \label{fig:4.7}
  \end{figure}

\section{Limitations \& Future Work}
This model does not work on high resolution images of two class problem.
For high class we use Res-Net architecture which is complex and
requires high computational power. We have used a variant of VGG-16 for
our five class problem. Highly complex model cause overfitting as model has
a minimal overfitting near 20 epochs. Moreover, hyperparameters tuning
plays an important role. Playing with the values of learning rate
and data can be recorded to have a detailed idea about the working
of various optimizers along with the variation of learning rate, exponential
decay etc. For future work, the detailed study about tuning of hyperparameters
is included.